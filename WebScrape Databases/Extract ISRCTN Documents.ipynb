{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory to download files\n",
    "default_download_dir = r\"C:\\Users\\je116\\Downloads\" \n",
    "download_dir = r\"C:\\Users\\je116\\OneDrive - Imperial College London\\PhD-wpca-je116\\9. Additional Projects\\Funding Awards\\09FEB2024 - Imperial BRC Digital Health Trials\\3. Survey\\Advertising\\WEBSCRAPE_ISRCTN_Relevant Documents\"\n",
    "\n",
    "# Function to download files based on the text label, with a custom filename\n",
    "def download_file_from_trial_output(clinical_trials_id):\n",
    "    try:\n",
    "        # Look for the div with the class \"Trial_outputs\"\n",
    "        trial_outputs = driver.find_element(By.CLASS_NAME, \"Trial_outputs\")\n",
    "\n",
    "        # Find the first file where the text is either \"Protocol\" or \"Statistical Analysis Plan\"\n",
    "        download_links = trial_outputs.find_elements(By.TAG_NAME, \"a\")  # Assuming the links are inside <a> tags\n",
    "\n",
    "        found_protocol = False\n",
    "        found_sap = False\n",
    "\n",
    "        for link in download_links:\n",
    "            link_text = link.text.strip().lower()  \n",
    "            \n",
    "            if not found_protocol and \"protocol\" in link_text:\n",
    "                found_protocol = True\n",
    "                file_url = link.get_attribute(\"href\")\n",
    "                file_type = \"Protocol\"\n",
    "                \n",
    "                link.click()\n",
    "                time.sleep(2) # Wait for the download to complete\n",
    "                \n",
    "                if len(driver.window_handles) > 2: \n",
    "                    driver.switch_to.window(driver.window_handles[-1])  # Switch to the new tab\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[1])\n",
    "                else:\n",
    "                    file_name = f\"{clinical_trials_id}_{file_type}.pdf\"\n",
    "                    download_path = os.path.join(download_dir, file_name)\n",
    "                    move_latest_file_to_destination(default_download_dir, download_path)\n",
    "\n",
    "            elif not found_sap and \"statistical analysis plan\" in link_text:\n",
    "                found_sap = True\n",
    "                file_url = link.get_attribute(\"href\")\n",
    "                file_type = \"SAP\"\n",
    "\n",
    "                link.click()\n",
    "                time.sleep(2) # Wait for the download to complete\n",
    "                \n",
    "                if len(driver.window_handles) > 2: \n",
    "                    driver.switch_to.window(driver.window_handles[-1])  # Switch to the new tab\n",
    "                    driver.close()\n",
    "                    driver.switch_to.window(driver.window_handles[1])\n",
    "                else:\n",
    "                    file_name = f\"{clinical_trials_id}_{file_type}.pdf\"\n",
    "                    download_path = os.path.join(download_dir, file_name)\n",
    "                    move_latest_file_to_destination(default_download_dir, download_path)\n",
    "\n",
    "            if found_protocol and found_sap:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "\n",
    "# Function to move the most recently downloaded file from default directory to the desired location\n",
    "def move_latest_file_to_destination(default_download_dir, destination_path):\n",
    "    try:\n",
    "        today = datetime.now().date() # Only look through today downloads\n",
    "        # Get a list of files in the default download directory\n",
    "        files = os.listdir(default_download_dir)\n",
    "\n",
    "        # Filter files by modified time, ensuring only files modified today are considered\n",
    "        today_files = [f for f in files if datetime.fromtimestamp(os.path.getmtime(os.path.join(default_download_dir, f))).date() == today]\n",
    "\n",
    "        # Sort today's files by modified time (most recent first)\n",
    "        today_files.sort(key=lambda x: os.path.getmtime(os.path.join(default_download_dir, x)), reverse=True)\n",
    "\n",
    "        # Find the latest file\n",
    "        latest_file = os.path.join(default_download_dir, today_files[0])\n",
    "\n",
    "        # Move the latest file to the destination path\n",
    "        shutil.move(latest_file, destination_path)\n",
    "        #print(f\"Moved file to {destination_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error moving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from each project page\n",
    "def extract_data(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Give the page some time to load\n",
    "    \n",
    "    # List of tuples containing the data keys and their corresponding XPaths\n",
    "    elements = [\n",
    "        ('Study Title'              , '/html/body/div[2]/div/div/header/div/h1'),\n",
    "        ('ClinicalTrialsID'         , '/html/body/div[2]/div/div/header/div/p/span[1]'),\n",
    "        ('Start Date'               , '/html/body/div[2]/div/div/div[2]/article/section[5]/div/div/p[8]'),\n",
    "        ('End Date'                 , '/html/body/div[2]/div/div/div[2]/article/section[5]/div/div/p[9]'),\n",
    "        ('Sample Size'              , '/html/body/div[2]/div/div/div[2]/article/section[5]/div/div/p[6]'),\n",
    "        ('Brief Summary'            , '/html/body/div[2]/div/div/div[2]/article/section[1]/div/div/p[1]'),\n",
    "        ('Design'                   , '/html/body/div[2]/div/div/div[2]/article/section[4]/div/div/p[5]'),\n",
    "        ('Condition'                , '/html/body/div[2]/div/div/div[2]/article/section[4]/div/div/p[11]'),\n",
    "        ('Intervention'             , '/html/body/div[2]/div/div/div[2]/article/section[4]/div/div/p[12]'),\n",
    "        ('Intervention Type'        , '/html/body/div[2]/div/div/div[2]/article/section[4]/div/div/p[13]'),\n",
    "        ('Contact Name'             , '/html/body/div[2]/div/div/div[2]/article/section[2]/div/div/p[2]'),\n",
    "        ('Contact Email'            , '/html/body/div[2]/div/div/div[2]/article/section[2]/div/div/p[4]/a'),\n",
    "        ('Principal Investigator'   , '/html/body/div[2]/div/div/div[2]/article/section[2]/div/div/p[6]')\n",
    "    ]\n",
    "    \n",
    "    data = {}\n",
    "    for key, xpath in elements:\n",
    "        try:\n",
    "            # Debugging\n",
    "            #print(key , end = \",\")\n",
    "            data[key] = driver.find_element(By.XPATH, xpath).text\n",
    "        except:\n",
    "            data[key] = None\n",
    "    \n",
    "    # Extract the ClinicalTrialsID to use for file naming\n",
    "    clinical_trials_id = data.get('ClinicalTrialsID')\n",
    "    \n",
    "    # Download the files from \"Trial_outputs\"\n",
    "    if clinical_trials_id:\n",
    "        download_file_from_trial_output(clinical_trials_id)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cookies button clicked.\n",
      "Gathering results for Digital Health Intervention\n",
      "Total Results: 735\n",
      "Results per Page: 10\n",
      "Total Pages: 74\n",
      ".........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........600.........610.........620.........630.........640.........650.........660.........670.........680.........690.........700.........710.........720.........730.....Cookies button not found, no click needed.\n",
      "Gathering results for mobile application\n",
      "Total Results: 224\n",
      "Results per Page: 10\n",
      "Total Pages: 23\n",
      ".........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220....Cookies button not found, no click needed.\n",
      "Gathering results for Internet Delivered Treatment\n",
      "Total Results: 348\n",
      "Results per Page: 10\n",
      "Total Pages: 35\n",
      ".........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340........Cookies button not found, no click needed.\n",
      "Gathering results for Website intervention\n",
      "Total Results: 1016\n",
      "Results per Page: 10\n",
      "Total Pages: 102\n",
      ".........10.........20.........30.........40.........50.........60.........70.........80.........90.........100.........110.........120.........130.........140.........150.........160.........170.........180.........190.........200.........210.........220.........230.........240.........250.........260.........270.........280.........290.........300.........310.........320.........330.........340.........350.........360.........370.........380.........390.........400.........410.........420.........430.........440.........450.........460.........470.........480.........490.........500.........510.........520.........530.........540.........550.........560.........570.........580.........590.........600.........610....Error moving file: list index out of range\n",
      "Error downloading file: Message: stale element reference: stale element not found\n",
      "  (Session info: chrome=128.0.6613.120); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0031D933+25811]\n",
      "\t(No symbol) [0x002AE314]\n",
      "\t(No symbol) [0x001A2523]\n",
      "\t(No symbol) [0x001B0BE5]\n",
      "\t(No symbol) [0x001A898C]\n",
      "\t(No symbol) [0x001A6CA7]\n",
      "\t(No symbol) [0x001A9988]\n",
      "\t(No symbol) [0x001A9A00]\n",
      "\t(No symbol) [0x001E2536]\n",
      "\t(No symbol) [0x0020AD2C]\n",
      "\t(No symbol) [0x001DD475]\n",
      "\t(No symbol) [0x0020AFC4]\n",
      "\t(No symbol) [0x002246F0]\n",
      "\t(No symbol) [0x0020AAC6]\n",
      "\t(No symbol) [0x001DBEFD]\n",
      "\t(No symbol) [0x001DC8FD]\n",
      "\tGetHandleVerifier [0x005EF143+2981091]\n",
      "\tGetHandleVerifier [0x00642FF9+3324825]\n",
      "\tGetHandleVerifier [0x003AB32F+605903]\n",
      "\tGetHandleVerifier [0x003B2CBC+637020]\n",
      "\t(No symbol) [0x002B6F4D]\n",
      "\t(No symbol) [0x002B3DD8]\n",
      "\t(No symbol) [0x002B3F75]\n",
      "\t(No symbol) [0x002A6406]\n",
      "\tBaseThreadInitThunk [0x75C7FCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x777D80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x777D809E+238]\n",
      "\t(No symbol) [0x00000000]\n",
      "\n",
      ".....620.........630Error moving file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\je116\\\\Downloads\\\\13054_2022_3921_MOESM1_ESM.pdf.crdownload'\n",
      "Error moving file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\je116\\\\Downloads\\\\13054_2022_3921_MOESM1_ESM (1).pdf.crdownload'\n",
      ".Error moving file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\je116\\\\Downloads\\\\13054_2022_3921_MOESM1_ESM (1).pdf.crdownload'\n",
      "Error moving file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\je116\\\\Downloads\\\\13054_2022_3921_MOESM1_ESM (1).pdf.crdownload'\n",
      "........640.........650.........660.........670.........680.........690.........700.........710.........720.........730.........740.........750.........760.........770.........780......Error moving file: [WinError 5] Access is denied: 'C:\\\\Users\\\\je116\\\\Downloads\\\\Unconfirmed 391975.crdownload'\n",
      "...790.........800.........810.........820.........830.........840.........850.........860.........870.........880.........890.........900.........910.........920.........930.........940.........950.........960.........970.........980.........990.........1000.........1010......Total records gathered: 2323\n"
     ]
    }
   ],
   "source": [
    "# Set up Chrome options to specify the download folder and disable the popup that asks for confirmation\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": default_download_dir,  # Set default download folder\n",
    "    \"download.prompt_for_download\": False,  # Disable download prompt\n",
    "    \"download.directory_upgrade\": True,\n",
    "    \"safebrowsing.enabled\": True\n",
    "})\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# List of search terms\n",
    "search_terms = [\n",
    "    \"Digital Health Intervention\",\n",
    "    \"mobile application\",\n",
    "    \"Internet Delivered Treatment\",\n",
    "    \"Website intervention\"\n",
    "]\n",
    "\n",
    "# Base URL parts\n",
    "base_url = \"https://www.isrctn.com/\"\n",
    "\n",
    "# Initialize a list to hold the data for all search terms\n",
    "all_results = []\n",
    "\n",
    "# Iterate through search terms and open the URLs\n",
    "for term in search_terms:\n",
    "    # Replace spaces with %20 for URL encoding\n",
    "    encoded_term = term.replace(\" \", \"+\")\n",
    "    \n",
    "    # Construct the full URL\n",
    "    url = f\"{base_url}search?q={encoded_term}\"\n",
    "    \n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Give the page some time to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    cookies_button_xpath = '/html/body/section/div/div[2]/button[2]'\n",
    "    cookies_button = driver.find_elements(By.XPATH, cookies_button_xpath)\n",
    "    \n",
    "    if cookies_button:\n",
    "        # Click the cookies button if it is present\n",
    "        cookies_button[0].click()\n",
    "        print(\"Cookies button clicked.\")\n",
    "    else:\n",
    "        print(\"Cookies button not found, no click needed.\")\n",
    "\n",
    "    print(f\"Gathering results for {term}\")\n",
    "    \n",
    "    # Get the total number of search results\n",
    "    total_results_xpath = \"/html/body/div[2]/div/div/div[1]/h1\"\n",
    "    total_results_string = driver.find_element(By.XPATH, total_results_xpath).text\n",
    "\n",
    "    # Use regex to find the number\n",
    "    total_results_match = re.search(r'(\\d+)\\s+results', total_results_string, re.DOTALL)\n",
    "    total_results = int(total_results_match.group(1))\n",
    "    print(f\"Total Results: {total_results}\")\n",
    "\n",
    "    # Calculate the total number of pages\n",
    "    total_pages_xpath = \"/html/body/div[2]/div/div/div[1]/div[1]/div/span[3]\"\n",
    "    total_pages_string = driver.find_element(By.XPATH, total_pages_xpath).text\n",
    "    total_pages_match = re.search(r'of (\\d+)', total_pages_string)\n",
    "    total_pages = int(total_pages_match.group(1))\n",
    "    results_per_page = math.ceil(total_results / total_pages)\n",
    "\n",
    "    print(f\"Results per Page: {results_per_page}\")\n",
    "    print(f\"Total Pages: {total_pages}\")\n",
    "\n",
    "    # Iterate over all the pages\n",
    "    for page in range(total_pages):\n",
    "        # Iterate through the search results on the current page\n",
    "        for i in range(1, results_per_page + 1):\n",
    "            if (page * results_per_page) + i > total_results:\n",
    "                break  # Stop if we've processed all results\n",
    "            try:\n",
    "                # Construct XPath to click onto each search result \n",
    "                xpath = f\"/html/body/div[2]/div/div/div[1]/ul/li[{i}]/article/div[1]/h3/a\"\n",
    "                \n",
    "                # Use WebDriverWait to wait until the element is present\n",
    "                link = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "                url = link.get_attribute('href')  # Get the href attribute\n",
    "                \n",
    "                # Open the link in a new tab\n",
    "                driver.execute_script(\"window.open(arguments[0]);\", url)\n",
    "                driver.switch_to.window(driver.window_handles[-1])  # Switch to the new tab\n",
    "                \n",
    "                # Extract data from the new tab\n",
    "                project_data = extract_data(url)\n",
    "                # Add the search term to the project data\n",
    "                project_data['search_term'] = term\n",
    "\n",
    "                all_results.append(project_data)\n",
    "                \n",
    "                # Close the tab and switch back to the original search page\n",
    "                driver.close()\n",
    "                driver.switch_to.window(driver.window_handles[0])\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    print(i * (page+1), end = \"\")\n",
    "                else:\n",
    "                    print(\".\", end = \"\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing result {i} on page {page + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Click the next button if there are more pages\n",
    "        if page < total_pages - 1:\n",
    "            try:\n",
    "                next_button_xpath = \"//a/span[contains(@class, 'Pager Pager--next')]\"\n",
    "                # next_button_xpath = '//nav/ul/li/button/span[contains(text(), \"Next\")]' # Find XPATH with \"Next\" in text      \n",
    "                next_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, next_button_xpath)))\n",
    "                next_button.click()\n",
    "                time.sleep(5)  # Wait for the next page to load\n",
    "            except Exception as e:\n",
    "                print(f\"Error clicking the next button on page {page + 1}: {e}\")\n",
    "                break\n",
    "\n",
    "# At the end, `all_results` will contain data from all search terms\n",
    "print(f\"Total records gathered: {len(all_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\je116\\OneDrive - Imperial College London\\PhD-wpca-je116\\9. Additional Projects\\Funding Awards\\09FEB2024 - Imperial BRC Digital Health Trials\\3. Survey\\Advertising\\WEBSCRAPE_ISRCTN_alltrials.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder location and filename for saving the CSV\n",
    "folder_path = r\"C:\\Users\\je116\\OneDrive - Imperial College London\\PhD-wpca-je116\\9. Additional Projects\\Funding Awards\\09FEB2024 - Imperial BRC Digital Health Trials\\3. Survey\\Advertising\"\n",
    "filename = \"WEBSCRAPE_ISRCTN_alltrials.csv\"\n",
    "csv_file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save results to CSV\n",
    "if all_results:\n",
    "    keys = all_results[0].keys()\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(all_results)\n",
    "    print(f\"Data saved to {csv_file_path}\")\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
